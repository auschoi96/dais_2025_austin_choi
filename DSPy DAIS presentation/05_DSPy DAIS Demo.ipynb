{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ba0efa1e-5b21-43f5-94cb-67840303d53f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Goal: \n",
    "This system is meant to be a workflow that triggers upon receving a PDF. For the demo, we want the agents to receive this PDF, determine what it is, then take corresponding action depending on what the original request was. Refer to the reference architecture below to understand how the agents are connected together.\n",
    "\n",
    "When runing this query, we only see one row of John Smith. We want to update this entry of John Smith with new information we provide from a medical discharge summary about John Smith. \n",
    "\n",
    "This demo uses DSPy because of its lightweight and pure python architecture. It makes it easy to organize and integrate with different python library and allows us to modularize our system, without locking us into some framework specific framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52cd1c7b-13aa-4d68-bb7f-9f4175d2933b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from config import catalog, schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aaedd59a-def9-4451-960c-fc584f740dd4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query = f\"SELECT * FROM {catalog}.{schema}.patient_visits WHERE first_name = 'John' AND last_name = 'Smith'\"\n",
    "df_john_smith = spark.sql(query)\n",
    "display(df_john_smith)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7d234c36-36b8-440a-b7e2-6bd84ab083c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Reference Architecture\n",
    "\n",
    "![ref](ref.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "160a1553-dd0f-44bd-8090-cf01dd476954",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Caveat!! \n",
    "\n",
    "1. It's a lot in one notebook! To demostrate this as a demo, a lot is compacted into one notebook. Please use software development best practices when organizing your code, especially the more modular aspects of this notebook \n",
    "2. Model Serving Endpoints and Vector Search Endpoints and Genie Spaces were all created ahead of this demo. Notebooks 01 to 04 all created this for you. If you have not done so, this will not work. \n",
    "3. This CANNOT run on serverless. You must use a Databricks Runtime ML 16.X or equivalent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da10ebd8-b753-4583-878e-ac8708ca4fcc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade --force-reinstall dspy mlflow transformers databricks-vectorsearch databricks-sdk requests pdf2image pillow markdown gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76d210bd-a7ba-4cf2-916f-cd710cfbd516",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install --pre -U dspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "73eff3b8-427a-4b78-85f6-4d8db541ff4b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sh\n",
    "sudo apt clean\n",
    "sudo apt update --fix-missing -y\n",
    "sudo apt-get install -y libpoppler-cpp-dev pkg-config poppler-utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "976112ab-60ee-4ed8-84d2-8cb7f3a43eed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a29c26ff-7aa3-4bd1-8170-ae3d55ebed37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger(\"py4j.clientserver\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"mlflow.tracking.client\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c9eba14-045f-4dfd-9b53-c528c04f4572",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dspy\n",
    "import os\n",
    "\n",
    "import mlflow\n",
    "import mlflow.deployments\n",
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.pyfunc import PythonModel\n",
    "from mlflow.types.schema import Schema, ColSpec, TensorSpec\n",
    "\n",
    "from PIL import Image\n",
    "import base64\n",
    "import io\n",
    "from io import BytesIO\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd \n",
    "import json\n",
    "import requests\n",
    "\n",
    "from typing import Literal, Any\n",
    "\n",
    "from databricks.vector_search.client import VectorSearchClient\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.sdk.service.dashboards import GenieAPI\n",
    "\n",
    "from pdf2image import convert_from_path\n",
    "from pyspark.sql.types import StringType, StructType, StructField, IntegerType\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import Row\n",
    "\n",
    "from IPython.display import Markdown\n",
    "\n",
    "mlflow.dspy.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "374d9921-f3ba-474b-86ca-a802c97ffe05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from config import volume_label, volume_name, catalog, schema, model_name, model_endpoint_name, embedding_table_name, embedding_table_name_index, registered_model_name, vector_search_endpoint_name, beit_model_name, tesseract_model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "465f60af-8aae-4713-a00f-4b172c4af2f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#The Development Lifecycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3bb9eff3-a9ba-44ed-877f-1273e958787a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Step 1: Ingest the Medical Summary\n",
    "\n",
    "This would ideally be in a Databricks Workflow to process the PDF immediately upon arrival after Autoloader or another ingestion method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c1d53971-6c31-44b9-8a0a-43c5c926d1bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Find PDFs and Install Poppler\n",
    "\n",
    "Poppler needs an extra step to work properly on Databricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87d2e309-6bbe-4104-9665-22bc6640b075",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "notebook_path = os.path.dirname(dbutils.notebook.entry_point.getDbutils().notebook().getContext().notebookPath().get())\n",
    "workspace_folder = f\"/Workspace{notebook_path}/sample_pdf_sbc\"\n",
    "files = os.listdir(workspace_folder)\n",
    "file_paths_list = [os.path.join(workspace_folder, f) for f in files if f.endswith('.pdf')]\n",
    "print(f\"Found {len(file_paths_list)} PDF files:\")\n",
    "for pdf in file_paths_list:\n",
    "    print(f\"  - {pdf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ace599a-93ad-48fa-acf5-60fd7f7c99f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def install_poppler_on_nodes():\n",
    "    \"\"\"\n",
    "    Install poppler on all cluster nodes\n",
    "    \"\"\"\n",
    "    import subprocess\n",
    "    import os\n",
    "    \n",
    "    try:\n",
    "        subprocess.run(['apt-get', 'update'], check=True)\n",
    "        subprocess.run(['apt-get', 'install', '-y', 'poppler-utils'], check=True)\n",
    "        print(\"Poppler installed successfully\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error installing poppler: {e}\")\n",
    "\n",
    "sc.range(1).foreach(lambda x: install_poppler_on_nodes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b3e3cfbf-e036-481d-9a95-93a9975c124a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Process the PDFs found in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "030daaf0-347f-43c6-a88e-1f460c659bdc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def process_all_pdfs(pdf_paths):\n",
    "    \"\"\"\n",
    "    Process all PDFs on driver node to avoid UDF distribution issues\n",
    "    \"\"\"\n",
    "    all_pages = []\n",
    "    \n",
    "    def resize_image(image, max_short_dimension=768, max_long_dimension=2000):\n",
    "        \"\"\"Resize image while maintaining aspect ratio\"\"\"\n",
    "        width, height = image.size\n",
    "        \n",
    "        if width > height:\n",
    "            scaling_factor = min(max_long_dimension / width, max_short_dimension / height)\n",
    "        else:\n",
    "            scaling_factor = min(max_short_dimension / width, max_long_dimension / height)\n",
    "        \n",
    "        if scaling_factor < 1:\n",
    "            new_width = int(width * scaling_factor)\n",
    "            new_height = int(height * scaling_factor)\n",
    "            return image.resize((new_width, new_height), Image.LANCZOS)\n",
    "        \n",
    "        return image\n",
    "    \n",
    "    for pdf_path in pdf_paths:\n",
    "        try:\n",
    "            if not os.path.exists(pdf_path):\n",
    "                print(f\"File not found: {pdf_path}\")\n",
    "                continue\n",
    "            \n",
    "            if not os.access(pdf_path, os.R_OK):\n",
    "                print(f\"File not readable: {pdf_path}\")\n",
    "                continue\n",
    "            \n",
    "            print(f\"Processing: {pdf_path}\")\n",
    "            \n",
    "            images = convert_from_path(\n",
    "                pdf_path, \n",
    "                dpi=100,\n",
    "                fmt='JPEG',\n",
    "                poppler_path='/usr/bin'  \n",
    "            )\n",
    "            \n",
    "            for i, image in enumerate(images):\n",
    "                resized_image = resize_image(image)\n",
    "                \n",
    "                if resized_image.mode != 'RGB':\n",
    "                    resized_image = resized_image.convert('RGB')\n",
    "                \n",
    "                quantized_image = resized_image.quantize(colors=256)\n",
    "     \n",
    "                quantized_image = quantized_image.convert('RGB')\n",
    "                \n",
    "                img_buffer = io.BytesIO()\n",
    "                quantized_image.save(img_buffer, format='JPEG', quality=70, optimize=True)\n",
    "                img_bytes = img_buffer.getvalue()\n",
    "                \n",
    "\n",
    "                base64_string = base64.b64encode(img_bytes).decode('utf-8')\n",
    "                \n",
    "                all_pages.append({\n",
    "                    'pdf_path': pdf_path,\n",
    "                    'page_number': i + 1,\n",
    "                    'base64_image': base64_string\n",
    "                })\n",
    "            \n",
    "            print(f\"Successfully processed {len(images)} pages from {pdf_path}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {pdf_path}: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            continue\n",
    "    \n",
    "    return all_pages\n",
    "  \n",
    "\n",
    "print(f\"Processing {len(file_paths_list)} PDFs...\")\n",
    "all_page_data = process_all_pdfs(file_paths_list)\n",
    "print(f\"Total pages processed: {len(all_page_data)}\")\n",
    "\n",
    "\n",
    "pdf_schema = StructType([\n",
    "    StructField(\"pdf_path\", StringType(), True),\n",
    "    StructField(\"page_number\", IntegerType(), True),\n",
    "    StructField(\"base64_image\", StringType(), True)\n",
    "])\n",
    "\n",
    "df_pages = spark.createDataFrame(all_page_data, pdf_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a967451-7402-46de-8b38-34fba9928cc8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_pages.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "61cab857-f793-4879-99d6-895ef6ce4cb7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Step 2: Build your tools on Databricks\n",
    "\n",
    "Databricks offers a broad suite of infrastrucutre that allows you manage and govern everything in one place. This allows us to utilize many services and custom code/models to use as tools for our Agents. Below, we walk through setting up tools to hit Model Serving, Genie Spaces and Vector Search. \n",
    "\n",
    "For DSPy, all you need to do is define a python function. There is no need to attach it to a framework specific type. All you need is some python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1a2d46a0-6588-468e-8883-001af275dfe9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Model Serving\n",
    "We host our vision models on Databricks Model Serving so that we can access and work with them with our data. The two we have ready is: \n",
    "1. Microsoft BeIT Open Source Vision Transformer \n",
    "2. Good Old Tesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85052675-3a61-42b4-a221-ded84554e5b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def vision_transformer_tool(url, task):\n",
    "    \"\"\"Used to classify an image. Use this to answer the user's question about an image\"\"\"\n",
    "    API_TOKEN = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().get()\n",
    "    DATABRICKS_URL = dbutils.notebook.entry_point.getDbutils().notebook().getContext().browserHostName().get()\n",
    "    if task == 'ocr':\n",
    "      model = tesseract_model_name\n",
    "      encoded_image = url\n",
    "      input_data = pd.DataFrame({'image': [encoded_image]})\n",
    "\n",
    "      input_json = input_data.to_json(orient='split')\n",
    "\n",
    "      payload = {\n",
    "          \"dataframe_split\": json.loads(input_json)\n",
    "      }\n",
    "\n",
    "      headers = {\"Context-Type\": \"text/json\", \"Authorization\": f\"Bearer {API_TOKEN}\"}\n",
    "\n",
    "      response = requests.post(\n",
    "          url=f\"https://{DATABRICKS_URL}/serving-endpoints/{model}/invocations\", json=payload, headers=headers\n",
    "      )\n",
    "\n",
    "      result2 = response.json()\n",
    "      print(result2['predictions'])\n",
    "      return result2['predictions']\n",
    "    \n",
    "    if task == 'classification':\n",
    "      model = beit_model_name\n",
    "      data = {\"inputs\": [url]}\n",
    "\n",
    "      headers = {\"Context-Type\": \"text/json\", \"Authorization\": f\"Bearer {API_TOKEN}\"}\n",
    "\n",
    "      response = requests.post(\n",
    "          url=f\"https://{DATABRICKS_URL}/serving-endpoints/{model}/invocations\", json=data, headers=headers\n",
    "      )\n",
    "\n",
    "      result = response.json()\n",
    "      print(result)\n",
    "      return result['predictions'][0]['0']['label']  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9dd10cd8-9baf-4750-b386-49dfaaf0ccbb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Let's test they work using the first page of the PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65289028-1124-40a0-89f7-a649a7d7814f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "one_base64_image = df_pages.select(\"base64_image\").limit(1).collect()[0][\"base64_image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af68a634-90ef-4cee-b04e-f813e87a0f4f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "classification = vision_transformer_tool(url=one_base64_image, task=\"classification\")\n",
    "ocr = vision_transformer_tool(url=one_base64_image, task=\"ocr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bab5621b-dfc2-4433-b8b6-83e8d3793666",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Genie Spaces\n",
    "\n",
    "Databricks provides an API to interact with your Genie Spaces, allowing you to do natural language sql queries on your structured data. We can rely on the integration with Databricks to ensure we make the most accurate query for our data. \n",
    "\n",
    "There is currently no programatic way to create a Genie Space. Make sure you created one based on the tables in notebook 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68f041d7-0efe-4341-8cfa-93da01304d83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def hls_patient_genie(patient_name):\n",
    "  \"\"\"This function queries a genie space for more information about a patient\"\"\" \n",
    "  w = WorkspaceClient()\n",
    "  genie_space_id = \"01effef4c7e113f9b8952cf568b49ac7\"\n",
    "\n",
    "  # Start a conversation\n",
    "  conversation = w.genie.start_conversation_and_wait(\n",
    "      space_id=genie_space_id,\n",
    "      content=f\"{patient_name} always limit to one result\"\n",
    "  )\n",
    "\n",
    "  response = w.genie.get_message_attachment_query_result(\n",
    "    space_id=genie_space_id,\n",
    "    conversation_id=conversation.conversation_id,\n",
    "    message_id=conversation.message_id,\n",
    "    attachment_id=conversation.attachments[0].attachment_id\n",
    "  )\n",
    "\n",
    "  return response.statement_response.result.data_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb21cd8a-c065-4bf0-88c3-52b6213380b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "hls_patient_genie(\"what kind of insurance does Sarah Roberts have\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "647751aa-cd4e-42fa-8638-5a7d72057d1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Vector Search\n",
    "\n",
    "For this example, insurance information is also hidden in other PDF files. Due to time, we have already generated the vector search index for these PDFs and will be using it in this demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a0befb3-323b-4e6a-8892-919209bac910",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "vs_client = VectorSearchClient()\n",
    "\n",
    "vector_search_endpoint_name = \"one-env-shared-endpoint-4\"\n",
    "index_name = f\"{embedding_table_name}_index\"\n",
    "index = vs_client.get_index(endpoint_name=vector_search_endpoint_name, index_name=f\"{catalog}.{schema}.{index_name}\")\n",
    "\n",
    "def vector_search_for_patient_pdf(self, text_query):\n",
    "    \"\"\"Pulls matching Insurance Documents based on the text_query\"\"\"\n",
    "    client = mlflow.deployments.get_deploy_client(\"databricks\") \n",
    "    response = client.predict(\n",
    "              endpoint=model_endpoint_name,\n",
    "              inputs={\"dataframe_split\": {\n",
    "                      \"columns\": [\"text\"],\n",
    "                      \"data\": [[text_query]]\n",
    "                      }\n",
    "              }\n",
    "            )\n",
    "    text_embedding = response['predictions']['predictions']['embedding']\n",
    "    index = vs_client.get_index(endpoint_name=vector_search_endpoint_name, index_name=f\"{catalog}.{schema}.{index_name}\")\n",
    "    results = index.similarity_search(num_results=3, columns=[\"base64_image\"], query_vector=text_embedding)\n",
    "    return results['result']['data_array'][0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a729c074-4972-4544-95f0-bec4967b63d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Step 3: Set up DSPy\n",
    "\n",
    "We use DSPy due to its lightweight framework and declarative approach. There are minimum dependencies and we can build our program modularly like we would in Python Code. \n",
    "\n",
    "There's no need to learn framework specific classes or wait for framework specifc integrations. If there's a pure python approach or an SDK, you can use it with DSPy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9b6cc7db-9ea1-4e7d-89c8-fbe3a1bc5046",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##DSPy LLM Configuration\n",
    "\n",
    "DSPy uses LiteLLM in the backend to give universal access to LLMs no matter the provider or if it's local (through ollama for example). \n",
    "\n",
    "All you need to do is change the string! No new libraries needed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31e497b1-2fce-4e0d-a04a-785720d8f7ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "claude = dspy.LM('databricks/databricks-claude-sonnet-4', cache=False)\n",
    "claude_anthropic = dspy.LM('anthropic/claude-sonnet-4-20250514', api_key=dbutils.secrets.get(scope = \"groq_key\", key = \"anthropic\"), cache=False)\n",
    "llama8b = dspy.LM(\"databricks/databricks-meta-llama-3-1-8b-instruct\", cache=False)\n",
    "llama4 = dspy.LM(\"databricks/databricks-llama-4-maverick\", cache=False)\n",
    "# openai_example = dspy.LM('openai/gpt-4o-mini', api_key='YOUR_OPENAI_API_KEY')\n",
    "# bedrock_example = dspy.LM('\"bedrock/anthropic.claude-3-sonnet-20240229-v1:0', AWS_ACCESS_KEY_ID=AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY=AWS_SECRET_ACCESS_KEY, AWS_REGION_NAME=AWS_REGION_NAME)\n",
    "dspy.configure(lm=claude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e138b9e5-7dd3-493e-8a57-3d8cebb7a0e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##DSPy BaseType\n",
    "\n",
    "DSPy BaseTypes are essentially Pydantic BaseModels that will help us with data validation. For our case, we will define a memory type so capture the conversation so far. \n",
    "\n",
    "Because DSPy is a pure python framework, you can really bring any typing or library you like to handle this like Langmem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9eff8db5-d454-4fc5-a58f-1f987266a30e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from typing import List, Any\n",
    "\n",
    "class memoryHistory(dspy.BaseType):\n",
    "  history: List[dict] \n",
    "  last_message: List[str]\n",
    "  summary_so_far: str\n",
    "  # placeholder: str\n",
    "\n",
    "  def format(self) -> list[dict[str, Any]]:\n",
    "    return [\n",
    "      {\n",
    "      \"type\": \"memory\", \n",
    "      \"memory\": {\n",
    "        \"history\": self.history, \n",
    "        \"message\": self.last_message, \n",
    "        \"summary\": self.summary_so_far,\n",
    "        \"placeholder\": self.placeholder,\n",
    "        }\n",
    "      }\n",
    "      ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9b037be-e9e4-4126-9286-f219c06e87cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "memory_history = memoryHistory(\n",
    "  history=[],\n",
    "  last_message=[],\n",
    "  summary_so_far=\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d3a139ff-5004-45a4-9c6b-83fa93e1fd59",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Step 4: Build your agents\n",
    "Great, now we have our resources ready. So let's build out our Agents that will interact with each other to complete the task. \n",
    "\n",
    "Remember, the goal is to update our Patient Database with up to date information about this patient based on the ambigious document we received. \n",
    "\n",
    "DSPy makes multi-agent development a breeze thanks to their declarative, pure python approach. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "618a7450-d3b1-46e4-94fb-0f96772ee4c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##DSPy Signatures \n",
    "\n",
    "Signatures allow you to enforce typing and modularize your code, allowing you to identify and tweak specific parts of your code, instead of a wall of text. \n",
    "\n",
    "DSPy will use EVERYTHING within a signature to adapt to a prompt. Your docstring is where you can do some prompt engineering if you wish but it is not necessary. You should use it like you would when writing good documentation (assuming you do write good documentation) \n",
    "\n",
    "Recommendation: Organize this into its own file to import where you like or use mlflow prompt registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6be3d6bc-b8c0-4018-845a-b8bfa1c9a02b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class text_summarizer_extraction(dspy.Signature): \n",
    "  \"\"\"Agent to summarize the ocr output and find keywords based on the original query.\"\"\"\n",
    "\n",
    "  ocr_input: str = dspy.InputField()\n",
    "  original_query: str = dspy.InputField()\n",
    "  memory_so_far: memoryHistory = dspy.InputField(desc=\"a history of the workflow so far\")\n",
    "  response: str = dspy.OutputField()\n",
    "  summary_so_far: str = dspy.OutputField()\n",
    "  keywords: str = dspy.OutputField()\n",
    "  next_agent_or_tool: Literal[\"text_processing_agent\", \"patient_lookup_genie_agent\", \"final_agent\"] = dspy.OutputField() \n",
    "\n",
    "class genie_agent(dspy.Signature): \n",
    "  \"\"\"Agent to use Databricks Genie Space to find information about a patient. It creates a question based on the provided keywords in patient_information or memory_history to query the genie_space with only the patient's name. Then, it takes the genie_output, makes a text_query based on insurance type, insurance name and keyterms like deductible found in both genie_outputs and original_query and sends the text_query to patient_insurance_lookup\"\"\"\n",
    "\n",
    "  patient_information: str = dspy.InputField(desc=\"Find the patient's name\")\n",
    "  original_query: str = dspy.InputField()\n",
    "  memory_so_far: memoryHistory = dspy.InputField(desc=\"a history of the workflow so far\")\n",
    "  genie_output: str = dspy.OutputField()\n",
    "  insurance_details: str = dspy.OutputField()\n",
    "  response: str = dspy.OutputField()\n",
    "  summary_so_far: str = dspy.OutputField()\n",
    "  deductible: str = dspy.OutputField(desc=\"this is the result of patient_insurance_lookup\")\n",
    "  next_agent_or_tool: Literal[\"text_processing_agent\", \"patient_lookup_genie_agent\", \"final_agent\"] = dspy.OutputField() \n",
    "\n",
    "class final_agent(dspy.Signature):\n",
    "  \"\"\"Agent to convert the collected information and write to a delta table based on the original_query.\"\"\" \n",
    "\n",
    "  original_query: str = dspy.InputField()\n",
    "  genie_output: list = dspy.InputField() \n",
    "  ocr_summary: str = dspy.InputField() \n",
    "  deductible: str = dspy.InputField()\n",
    "  completed_response: str = dspy.OutputField()\n",
    "\n",
    "class document_analyzer(dspy.Signature):\n",
    "  \"\"\"Agent to analyze the document provided by reviewing the outputs of the model and determining if there's enough information to go to the next agent or try analyzing the document again with a different vision model\"\"\" \n",
    "\n",
    "  vision_model_output: str = dspy.InputField()\n",
    "  response: str = dspy.OutputField() \n",
    "  next_agent_or_tool: Literal[\"text_processing_agent\", \"patient_lookup_genie_agent\", \"final_agent\"] = dspy.OutputField() \n",
    "\n",
    "class insurance_finder(dspy.Signature):\n",
    "  \"\"\"Find the relevant information based on the text_query within the image\"\"\"\n",
    "\n",
    "  image: dspy.Image = dspy.InputField()\n",
    "  text_query: str = dspy.InputField()\n",
    "  deductible: str = dspy.OutputField()\n",
    "  other_information: str = dspy.OutputField()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cee76a4b-7ef8-49dd-83a2-a93081cc87e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Step 5: Test your Agents independently to ensure they work \n",
    "\n",
    "Before putting our agents together, we can use prebuilt DSPy modules like dspy.Predict and dspy.ReAct to ensure that the signatures are performing as we expect them to. \n",
    "\n",
    "Let's try them out below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d161f36-ae2f-42f1-af10-ba400d2b6b1e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ocr_processing = dspy.Predict(text_summarizer_extraction)\n",
    "outputs = ocr_processing(ocr_input=ocr, original_query=\"Update the patient's information based on this document and find their deductible if it's not in the table\", memory_so_far=memory_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43da4e41-3a81-468d-a598-039658ac818d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7713ea5-e3d1-4cd6-880b-5b15e5cde98d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "patient_lookup = dspy.ReAct(genie_agent, tools=[hls_patient_genie], max_iters=1)\n",
    "genie_outputs = patient_lookup(patient_information=outputs.keywords, memory_so_far=memory_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8bac3696-23a2-4386-a3e2-2aa1c3407c48",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(genie_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f2788762-5f89-40db-8fad-72006fc9c31f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Step 6: Put it all together in a custom DSPy Module\n",
    "\n",
    "DSPy gives you the freedom to program your own module. Below, you'll see the custom module that packages everything you saw above into one class. We can then execute that class in one line. \n",
    "\n",
    "Everything follows object oriented programming and familiar patterns like Pytorch's forward method. Additionally, you can add any custom python logic within this module so that you don't have to completely rely on the agent to do everything. You know exactly what is happening and can control the flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c52d1a6-6183-4fdc-91b0-5087e8b703a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class dais_document_ingestor(dspy.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.patient_lookup_genie_agent = dspy.ReAct(genie_agent, tools=[self.hls_patient_genie, self.patient_insurance_lookup], max_iters=2)\n",
    "    self.text_processing_agent = dspy.Predict(text_summarizer_extraction)\n",
    "    self.final_agent = dspy.ReAct(final_agent, tools=[self.final_write_to_table], max_iters=1) #likely a tool call\n",
    "    self.document_analyzer_agent = dspy.Predict(document_analyzer)\n",
    "    self.insurance_finder = dspy.Predict(insurance_finder)\n",
    "    self.memory_history = memoryHistory(history=[],\n",
    "                                        last_message=[],\n",
    "                                        summary_so_far=\"\"\n",
    "                                        )\n",
    "\n",
    "  def patient_insurance_lookup(self, text_query):\n",
    "    \"\"\"Pulls matching Insurance Documents based on the text_query\"\"\"\n",
    "    print(f\"Starting patient insurance look up with results: {text_query}\\n\\n\")\n",
    "    # patient_insurance_extraction = dspy.Predict(\"genie_outputs-> patient_name_and_insurance_details: str\")\n",
    "    # text_query = patient_insurance_extraction(genie_outputs=genie_outputs).patient_name_and_insurance_details\n",
    "    print(f\"The Text query being sent for vector search: {text_query}\\n\\n\")\n",
    "    vs_client = VectorSearchClient()\n",
    "    vector_search_endpoint_name = \"one-env-shared-endpoint-4\"\n",
    "    index_name = f\"{embedding_table_name}_index\"\n",
    "    client = mlflow.deployments.get_deploy_client(\"databricks\") \n",
    "    response = client.predict(\n",
    "              endpoint=model_endpoint_name,\n",
    "              # endpoint=model_name,\n",
    "              inputs={\"dataframe_split\": {\n",
    "                      \"columns\": [\"text\"],\n",
    "                      \"data\": [[text_query]]\n",
    "                      }\n",
    "              }\n",
    "            )\n",
    "    text_embedding = response['predictions']['predictions']['embedding']\n",
    "    index = vs_client.get_index(endpoint_name=vector_search_endpoint_name, index_name=f\"{catalog}.{schema}.{index_name}\")\n",
    "    results = index.similarity_search(num_results=3, columns=[\"base64_image\"], query_vector=text_embedding)\n",
    "    base64_string = results['result']['data_array'][0][0]\n",
    "    image_data = base64.b64decode(base64_string) \n",
    "    pil_image = Image.open(io.BytesIO(image_data))\n",
    "    dspy_image = dspy.Image.from_PIL(pil_image)\n",
    "    with dspy.context(lm=claude_anthropic):\n",
    "      print(f\"Reviewing Vector Search Results\\n\\nCurrent Model: {claude_anthropic}\\n\\n\")\n",
    "      deductible = self.insurance_finder(image=dspy_image, text_query=text_query)\n",
    "    return deductible.deductible\n",
    "  \n",
    "  def hls_patient_genie(self, patient_name):\n",
    "    \"\"\"This function queries a genie space for more information about a patient\"\"\" \n",
    "    w = WorkspaceClient()\n",
    "    genie_space_id = \"01effef4c7e113f9b8952cf568b49ac7\"\n",
    "\n",
    "    # Start a conversation\n",
    "    conversation = w.genie.start_conversation_and_wait(\n",
    "        space_id=genie_space_id,\n",
    "        content=f\"{patient_name} always limit to one result\"\n",
    "    )\n",
    "\n",
    "    response = w.genie.get_message_attachment_query_result(\n",
    "      space_id=genie_space_id,\n",
    "      conversation_id=conversation.conversation_id,\n",
    "      message_id=conversation.message_id,\n",
    "      attachment_id=conversation.attachments[0].attachment_id\n",
    "    )\n",
    "\n",
    "    return response.statement_response.result.data_array\n",
    "  \n",
    "\n",
    "  def document_analyzer_tool(self, task, medical_summary_df):\n",
    "    \"\"\"Used to analyze a document. Medical_Summary_df should be a dataframe and task is either ocr or classification\"\"\"\n",
    "    API_TOKEN = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().get()\n",
    "    DATABRICKS_URL = dbutils.notebook.entry_point.getDbutils().notebook().getContext().browserHostName().get()\n",
    "    encoded_image = medical_summary_df.select(\"base64_image\").limit(1).collect()[0][\"base64_image\"]\n",
    "    if task == 'ocr':\n",
    "      model = tesseract_model_name\n",
    "      x = 0 \n",
    "      full_text = []\n",
    "      for x in range(len(df_pages.collect())):\n",
    "        encoded_image = df_pages.select(\"base64_image\").collect()[x][\"base64_image\"]\n",
    "        input_data = pd.DataFrame({'image': [encoded_image]})\n",
    "\n",
    "        input_json = input_data.to_json(orient='split')\n",
    "\n",
    "        payload = {\n",
    "            \"dataframe_split\": json.loads(input_json)\n",
    "        }\n",
    "\n",
    "        headers = {\"Context-Type\": \"text/json\", \"Authorization\": f\"Bearer {API_TOKEN}\"}\n",
    "\n",
    "        response = requests.post(\n",
    "            url=f\"https://{DATABRICKS_URL}/serving-endpoints/{model}/invocations\", json=payload, headers=headers\n",
    "        )\n",
    "\n",
    "        result2 = response.json()\n",
    "        full_text.append(result2['predictions'])\n",
    "        x+=1\n",
    "      return full_text\n",
    "    \n",
    "    if task == 'classification':\n",
    "      model = beit_model_name\n",
    "      data = {\"inputs\": [encoded_image]}\n",
    "\n",
    "      headers = {\"Context-Type\": \"text/json\", \"Authorization\": f\"Bearer {API_TOKEN}\"}\n",
    "\n",
    "      response = requests.post(\n",
    "          url=f\"https://{DATABRICKS_URL}/serving-endpoints/{model}/invocations\", json=data, headers=headers\n",
    "      )\n",
    "\n",
    "      result = response.json()\n",
    "      return result['predictions'][0]['0']['label']  \n",
    "    \n",
    "  def process_agent_response(self, memory_history: memoryHistory, response: str, summary_so_far: str):\n",
    "    \"\"\"Helper method to process agent responses and determine next steps\"\"\"\n",
    "    memory_history.history.append(response)\n",
    "    memory_history.summary_so_far = summary_so_far\n",
    "    return memory_history\n",
    "  \n",
    "  def final_write_to_table(self, original_query, genie_output, ocr_summary, delta_table, deductible):\n",
    "    \"\"\"Spark code to write to the table the original_query specified\"\"\" \n",
    "    print(f\"This is the final_write function\\n\\nGenie Output {genie_output}\\n\\nOrigina_query: {original_query}\\n\\nOCR Summary: {ocr_summary}\\n\\nDeductible: {deductible}\\n\\nDelta Table Name: {delta_table}\")\n",
    "    insert_data = [\n",
    "      Row(first_name = genie_output[0],\n",
    "      last_name = genie_output[1],\n",
    "      insurance_provider_name = genie_output[2],\n",
    "      insurance_type = genie_output[3],\n",
    "      insurance_policy_number=genie_output[4],\n",
    "      email=genie_output[5],\n",
    "      city=genie_output[6],\n",
    "      practice_visited_practice_id=int(genie_output[7]),\n",
    "      doctor_notes=ocr_summary,\n",
    "      deductible=deductible)\n",
    "    ]\n",
    "    df_with_new_column = spark.createDataFrame(insert_data)\n",
    "    df_with_new_column.write.format(\"delta\").mode(\"append\").option(\"mergeSchema\", \"true\").saveAsTable(delta_table)\n",
    "    \n",
    "    return \"placehoolder\"\n",
    "\n",
    "  \n",
    "  def handle_question(self, original_query, medical_summary_df, next_agent, memory_history, agent_response, ocr_result):\n",
    "    \"\"\"Processes a document given to the agent. Multiple agents work together using a variety of LLMs to solve the workflow\"\"\"\n",
    "    next_agent = next_agent\n",
    "    print(\"Beginning Agent Interaction\\n\\n\")\n",
    "    while True:\n",
    "        if next_agent == 'text_processing_agent':\n",
    "          print(\"Text Extract AGENT STARTING\\n\\n\")\n",
    "          with dspy.context(lm=llama4):\n",
    "            print(f\"Current Model: {llama4}\\n\\n\")\n",
    "            text_agent_response = self.text_processing_agent(\n",
    "                ocr_input=ocr_result,\n",
    "                original_query=original_query,\n",
    "                memory_so_far=memory_history\n",
    "            )\n",
    "          memory_history = self.process_agent_response(memory_history=memory_history, response=text_agent_response.response, summary_so_far=text_agent_response.summary_so_far)\n",
    "          agent_response = text_agent_response.response\n",
    "          next_agent = text_agent_response.next_agent_or_tool\n",
    "          print(f\"Completed Text AGENT... Moving to {next_agent}\\n\\n\")\n",
    "          continue\n",
    "\n",
    "        elif next_agent == 'patient_lookup_genie_agent':\n",
    "          print(\"Patient Look Up Genie AGENT STARTING\\n\")\n",
    "          with dspy.context(lm=claude):\n",
    "            print(f\"Current Model: {claude}\\n\\n\")\n",
    "            genie_agent_response = self.patient_lookup_genie_agent(\n",
    "                patient_information=ocr_result,\n",
    "                original_query=original_query,\n",
    "                memory_so_far=memory_history\n",
    "            )\n",
    "          memory_history = self.process_agent_response(memory_history=memory_history, response=genie_agent_response.response,summary_so_far=genie_agent_response.summary_so_far)\n",
    "          agent_response = genie_agent_response.response\n",
    "          next_agent = genie_agent_response.next_agent_or_tool\n",
    "          print(f\"Completed Patient Look Up Genie... Moving to {next_agent}\\n\\n\")\n",
    "          continue\n",
    "\n",
    "        elif next_agent == 'final_agent':\n",
    "          print(\"Wrapping up with the final_agent\\n\")\n",
    "          with dspy.context(lm=claude):\n",
    "            print(f\"Current Model: {claude}\\n\\n\")\n",
    "            final_agent_response = self.final_agent(\n",
    "                original_query=original_query,\n",
    "                genie_output=genie_agent_response.genie_output,\n",
    "                ocr_summary=text_agent_response.summary_so_far,\n",
    "                deductible=genie_agent_response.deductible\n",
    "            )\n",
    "          \n",
    "          break\n",
    "\n",
    "    return final_agent_response.completed_response\n",
    "  \n",
    "  def forward(self, initial_query: str, medical_summary_df):\n",
    "    \"\"\"Main interaction loop\"\"\"\n",
    "    next_agent = \"\"\n",
    "    memory_history = memoryHistory(\n",
    "      history=[],\n",
    "      last_message=[],\n",
    "      summary_so_far=\"\"\n",
    "    )\n",
    "    vision_model_output = self.document_analyzer_tool(task='classification',medical_summary_df=medical_summary_df)\n",
    "    with dspy.context(lm=llama4):\n",
    "      document_analyzer_results = self.document_analyzer_agent(vision_model_output=vision_model_output)\n",
    "    print(f\"Image Analyzer Agent Response: {document_analyzer_results.response}\\n\\n\")\n",
    "\n",
    "    vision_model_output = self.document_analyzer_tool(task='ocr',medical_summary_df=medical_summary_df)\n",
    "    with dspy.context(lm=llama4):\n",
    "      document_analyzer_results = self.document_analyzer_agent(vision_model_output=vision_model_output)\n",
    "    print(f\"Image Analyzer Agent Response: {document_analyzer_results.response}\\n\\n\")\n",
    "    print(\"Completed Image Analysis. Handing off to Handle_Question to begin Agent Interaction\\n\\n\")\n",
    "    results = self.handle_question(original_query=initial_query, next_agent=document_analyzer_results.next_agent_or_tool, medical_summary_df=medical_summary_df, memory_history=memory_history, agent_response=document_analyzer_results.response, ocr_result = vision_model_output)\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7bd08a3c-9d07-4f1b-8170-98f98dca1962",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "original_query = \"Update the austin_choi_demo_catalog.agents.patient_visits table with information from the document. Also, add their insurance deductible to the table.\"\n",
    "\n",
    "dais_ingestor_agent = dais_document_ingestor()\n",
    "dais_output = dais_ingestor_agent(initial_query=original_query, medical_summary_df=df_pages)\n",
    "Markdown(dais_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62da84ca-6c6a-4226-b092-b5b4fb35d92a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query = f\"SELECT * FROM {catalog}.{schema}.patient_visits WHERE first_name = 'John' AND last_name = 'Smith'\"\n",
    "df_john_smith = spark.sql(query)\n",
    "display(df_john_smith)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90dd3669-d783-4519-b528-81d5d6758ced",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query = f\"ALTER TABLE {catalog}.{schema}.patient_visits DROP COLUMN deductible\"\n",
    "df_john_smith = spark.sql(query)\n",
    "display(df_john_smith)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b80878a1-0891-478c-a0ea-a6f98fa14528",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query = f\"DELETE FROM {catalog}.{schema}.patient_visits WHERE first_name = 'John' AND last_name = 'Smith' AND reason_for_visit is NULL\"\n",
    "df_john_smith = spark.sql(query)\n",
    "display(df_john_smith)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b32cc2f0-8a87-42d2-a1bd-a8e8159db7e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Congrats! The demo is complete\n",
    "\n",
    "If you want to see the demo in a gradio UI, run the code below! You'll need to manually upload the sample_pdf_sbc document located in the folder!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f60b4262-25c3-49fe-8c4a-cdecc3ee7bd2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import base64\n",
    "from PIL import Image\n",
    "import io\n",
    "from typing import List, Tuple\n",
    "import tempfile\n",
    "import os\n",
    "from pdf2image import convert_from_path\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "import traceback\n",
    "\n",
    "class dais_document_ingestor(dspy.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.patient_lookup_genie_agent = dspy.ReAct(genie_agent, tools=[self.hls_patient_genie, self.patient_insurance_lookup], max_iters=2)\n",
    "    self.text_processing_agent = dspy.Predict(text_summarizer_extraction)\n",
    "    self.final_agent = dspy.ReAct(final_agent, tools=[self.final_write_to_table], max_iters=1) #likely a tool call\n",
    "    self.document_analyzer_agent = dspy.Predict(document_analyzer)\n",
    "    self.insurance_finder = dspy.Predict(insurance_finder)\n",
    "    self.memory_history = memoryHistory(history=[],\n",
    "                                        last_message=[],\n",
    "                                        summary_so_far=\"\"\n",
    "                                        )\n",
    "\n",
    "  def patient_insurance_lookup(self, text_query):\n",
    "    \"\"\"Pulls matching Insurance Documents based on the text_query\"\"\"\n",
    "    print(f\"Starting patient insurance look up with results: {text_query}\\n\\n\")\n",
    "    # patient_insurance_extraction = dspy.Predict(\"genie_outputs-> patient_name_and_insurance_details: str\")\n",
    "    # text_query = patient_insurance_extraction(genie_outputs=genie_outputs).patient_name_and_insurance_details\n",
    "    print(f\"The Text query being sent for vector search: {text_query}\\n\\n\")\n",
    "    vs_client = VectorSearchClient()\n",
    "    vector_search_endpoint_name = \"one-env-shared-endpoint-4\"\n",
    "    index_name = f\"{embedding_table_name}_index\"\n",
    "    client = mlflow.deployments.get_deploy_client(\"databricks\") \n",
    "    response = client.predict(\n",
    "              endpoint=model_endpoint_name,\n",
    "              # endpoint=model_name,\n",
    "              inputs={\"dataframe_split\": {\n",
    "                      \"columns\": [\"text\"],\n",
    "                      \"data\": [[text_query]]\n",
    "                      }\n",
    "              }\n",
    "            )\n",
    "    text_embedding = response['predictions']['predictions']['embedding']\n",
    "    index = vs_client.get_index(endpoint_name=vector_search_endpoint_name, index_name=f\"{catalog}.{schema}.{index_name}\")\n",
    "    results = index.similarity_search(num_results=3, columns=[\"base64_image\"], query_vector=text_embedding)\n",
    "    base64_string = results['result']['data_array'][0][0]\n",
    "    image_data = base64.b64decode(base64_string) \n",
    "    pil_image = Image.open(io.BytesIO(image_data))\n",
    "    dspy_image = dspy.Image.from_PIL(pil_image)\n",
    "    with dspy.context(lm=claude_anthropic):\n",
    "      print(f\"Reviewing Vector Search Results\\n\\nCurrent Model: {claude_anthropic}\\n\\n\")\n",
    "      deductible = self.insurance_finder(image=dspy_image, text_query=text_query)\n",
    "    return deductible.deductible\n",
    "  \n",
    "  def hls_patient_genie(self, patient_name):\n",
    "    \"\"\"This function queries a genie space for more information about a patient\"\"\" \n",
    "    w = WorkspaceClient()\n",
    "    genie_space_id = \"01effef4c7e113f9b8952cf568b49ac7\"\n",
    "\n",
    "    # Start a conversation\n",
    "    conversation = w.genie.start_conversation_and_wait(\n",
    "        space_id=genie_space_id,\n",
    "        content=f\"{patient_name} always limit to one result\"\n",
    "    )\n",
    "\n",
    "    response = w.genie.get_message_attachment_query_result(\n",
    "      space_id=genie_space_id,\n",
    "      conversation_id=conversation.conversation_id,\n",
    "      message_id=conversation.message_id,\n",
    "      attachment_id=conversation.attachments[0].attachment_id\n",
    "    )\n",
    "\n",
    "    return response.statement_response.result.data_array\n",
    "  \n",
    "\n",
    "  def document_analyzer_tool(self, task, medical_summary_df):\n",
    "    \"\"\"Used to analyze a document. Medical_Summary_df should be a dataframe and task is either ocr or classification\"\"\"\n",
    "    API_TOKEN = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().get()\n",
    "    DATABRICKS_URL = dbutils.notebook.entry_point.getDbutils().notebook().getContext().browserHostName().get()\n",
    "    encoded_image = medical_summary_df.select(\"base64_image\").limit(1).collect()[0][\"base64_image\"]\n",
    "    if task == 'ocr':\n",
    "      model = tesseract_model_name\n",
    "      x = 0 \n",
    "      full_text = []\n",
    "      for x in range(len(df_pages.collect())):\n",
    "        encoded_image = df_pages.select(\"base64_image\").collect()[x][\"base64_image\"]\n",
    "        input_data = pd.DataFrame({'image': [encoded_image]})\n",
    "\n",
    "        input_json = input_data.to_json(orient='split')\n",
    "\n",
    "        payload = {\n",
    "            \"dataframe_split\": json.loads(input_json)\n",
    "        }\n",
    "\n",
    "        headers = {\"Context-Type\": \"text/json\", \"Authorization\": f\"Bearer {API_TOKEN}\"}\n",
    "\n",
    "        response = requests.post(\n",
    "            url=f\"https://{DATABRICKS_URL}/serving-endpoints/{model}/invocations\", json=payload, headers=headers\n",
    "        )\n",
    "\n",
    "        result2 = response.json()\n",
    "        full_text.append(result2['predictions'])\n",
    "        x+=1\n",
    "      return full_text\n",
    "    \n",
    "    if task == 'classification':\n",
    "      model = beit_model_name\n",
    "      data = {\"inputs\": [encoded_image]}\n",
    "\n",
    "      headers = {\"Context-Type\": \"text/json\", \"Authorization\": f\"Bearer {API_TOKEN}\"}\n",
    "\n",
    "      response = requests.post(\n",
    "          url=f\"https://{DATABRICKS_URL}/serving-endpoints/{model}/invocations\", json=data, headers=headers\n",
    "      )\n",
    "\n",
    "      result = response.json()\n",
    "      return result['predictions'][0]['0']['label']  \n",
    "    \n",
    "  def process_agent_response(self, memory_history: memoryHistory, response: str, summary_so_far: str):\n",
    "    \"\"\"Helper method to process agent responses and determine next steps\"\"\"\n",
    "    memory_history.history.append(response)\n",
    "    memory_history.summary_so_far = summary_so_far\n",
    "    return memory_history\n",
    "  \n",
    "  def final_write_to_table(self, original_query, genie_output, ocr_summary, delta_table, deductible):\n",
    "    \"\"\"Spark code to write to the table the original_query specified\"\"\" \n",
    "    print(f\"This is the final_write function\\n\\nGenie Output {genie_output}\\n\\nOrigina_query: {original_query}\\n\\nOCR Summary: {ocr_summary}\\n\\nDeductible: {deductible}\\n\\nDelta Table Name: {delta_table}\")\n",
    "    insert_data = [\n",
    "      Row(first_name = genie_output[0],\n",
    "      last_name = genie_output[1],\n",
    "      insurance_provider_name = genie_output[2],\n",
    "      insurance_type = genie_output[3],\n",
    "      insurance_policy_number=genie_output[4],\n",
    "      email=genie_output[5],\n",
    "      city=genie_output[6],\n",
    "      practice_visited_practice_id=int(genie_output[7]),\n",
    "      doctor_notes=ocr_summary,\n",
    "      deductible=deductible)\n",
    "    ]\n",
    "    df_with_new_column = spark.createDataFrame(insert_data)\n",
    "    df_with_new_column.write.format(\"delta\").mode(\"append\").option(\"mergeSchema\", \"true\").saveAsTable(delta_table)\n",
    "    \n",
    "    return \"placehoolder\"\n",
    "\n",
    "  \n",
    "  def handle_question(self, original_query, medical_summary_df, next_agent, memory_history, agent_response, ocr_result, progress=gr.Progress()):\n",
    "    \"\"\"Processes a document given to the agent. Multiple agents work together using a variety of LLMs to solve the workflow\"\"\"\n",
    "    next_agent = next_agent\n",
    "    progress_number = 0.55\n",
    "    print(\"Beginning Agent Interaction\\n\\n\")\n",
    "    while True:\n",
    "        if next_agent == 'text_processing_agent':\n",
    "          print(\"Text Extract AGENT STARTING\\n\\n\")\n",
    "          with dspy.context(lm=llama4):\n",
    "            # print(f\"Current Model: {llama4}\\n\\n\")\n",
    "            text_agent_response = self.text_processing_agent(\n",
    "                ocr_input=ocr_result,\n",
    "                original_query=original_query,\n",
    "                memory_so_far=memory_history\n",
    "            )\n",
    "          memory_history = self.process_agent_response(memory_history=memory_history, response=text_agent_response.response, summary_so_far=text_agent_response.summary_so_far)\n",
    "          agent_response = text_agent_response.response\n",
    "          next_agent = text_agent_response.next_agent_or_tool\n",
    "          # print(f\"Completed Text AGENT... Moving to {next_agent}\\n\\n\")\n",
    "          progress(progress_number+0.1, f\"Completed Text AGENT... Moving to {next_agent}\\n\\n\")\n",
    "          continue\n",
    "\n",
    "        elif next_agent == 'patient_lookup_genie_agent':\n",
    "          print(\"Patient Look Up Genie AGENT STARTING\\n\")\n",
    "          with dspy.context(lm=claude):\n",
    "            # print(f\"Current Model: {claude}\\n\\n\")\n",
    "            genie_agent_response = self.patient_lookup_genie_agent(\n",
    "                patient_information=ocr_result,\n",
    "                original_query=original_query,\n",
    "                memory_so_far=memory_history\n",
    "            )\n",
    "          memory_history = self.process_agent_response(memory_history=memory_history, response=genie_agent_response.response,summary_so_far=genie_agent_response.summary_so_far)\n",
    "          agent_response = genie_agent_response.response\n",
    "          next_agent = genie_agent_response.next_agent_or_tool\n",
    "          # print(f\"Completed Patient Look Up Genie... Moving to {next_agent}\\n\\n\")\n",
    "          progress(progress_number+0.3, f\"Completed Patient Look Up Genie... Moving to {next_agent}\\n\\n\")\n",
    "          continue\n",
    "\n",
    "        elif next_agent == 'final_agent':\n",
    "          # print(\"Wrapping up with the final_agent\\n\")\n",
    "          with dspy.context(lm=claude):\n",
    "            # print(f\"Current Model: {claude}\\n\\n\")\n",
    "            final_agent_response = self.final_agent(\n",
    "                original_query=original_query,\n",
    "                genie_output=genie_agent_response.genie_output,\n",
    "                ocr_summary=text_agent_response.summary_so_far,\n",
    "                deductible=genie_agent_response.deductible\n",
    "            )\n",
    "            progress(0.95, f\"Completed Final Agent... Finalizing...\\n\\n\")\n",
    "          \n",
    "          break\n",
    "\n",
    "    return final_agent_response.completed_response\n",
    "  \n",
    "  def forward(self, initial_query: str, medical_summary_df, progress=gr.Progress()):\n",
    "    \"\"\"Main interaction loop\"\"\"\n",
    "    next_agent = \"\"\n",
    "    memory_history = memoryHistory(\n",
    "      history=[],\n",
    "      last_message=[],\n",
    "      summary_so_far=\"\"\n",
    "    )\n",
    "    vision_model_output = self.document_analyzer_tool(task='classification',medical_summary_df=medical_summary_df)\n",
    "    with dspy.context(lm=llama4):\n",
    "      document_analyzer_results = self.document_analyzer_agent(vision_model_output=vision_model_output)\n",
    "    # print(f\"Image Analyzer Agent Response: {document_analyzer_results.response}\\n\\n\")\n",
    "    progress(0.4, desc=f\"Image Analyzer Agent Response: {document_analyzer_results.response}\\n\\n\")\n",
    "\n",
    "    vision_model_output = self.document_analyzer_tool(task='ocr',medical_summary_df=medical_summary_df)\n",
    "    with dspy.context(lm=llama4):\n",
    "      document_analyzer_results = self.document_analyzer_agent(vision_model_output=vision_model_output)\n",
    "    # print(f\"Image Analyzer Agent Response: {document_analyzer_results.response}\\n\\n\")\n",
    "    progress(0.45, desc=f\"Image Analyzer Agent Response: {document_analyzer_results.response}\\n\\n\")\n",
    "    # print(\"Completed Image Analysis. Handing off to Handle_Question to begin Agent Interaction\\n\\n\")\n",
    "    progress(0.5, desc=\"Completed Image Analysis. Handing off to Handle_Question to begin Agent Interaction\\n\\n\")\n",
    "    results = self.handle_question(original_query=initial_query, next_agent=document_analyzer_results.next_agent_or_tool, medical_summary_df=medical_summary_df, memory_history=memory_history, agent_response=document_analyzer_results.response, ocr_result = vision_model_output)\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e3e7576-b1aa-4bdd-a163-cc9d100d237a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the document ingestor\n",
    "dais_ingestor_agent = dais_document_ingestor()\n",
    "\n",
    "def process_all_pdfs(pdf_paths):\n",
    "    \"\"\"\n",
    "    Process all PDFs on driver node to avoid UDF distribution issues\n",
    "    \"\"\"\n",
    "    all_pages = []\n",
    "    \n",
    "    def resize_image(image, max_short_dimension=768, max_long_dimension=2000):\n",
    "        \"\"\"Resize image while maintaining aspect ratio\"\"\"\n",
    "        width, height = image.size\n",
    "        if width > height:\n",
    "            scaling_factor = min(max_long_dimension / width, max_short_dimension / height)\n",
    "        else:\n",
    "            scaling_factor = min(max_short_dimension / width, max_long_dimension / height)\n",
    "        \n",
    "        if scaling_factor < 1:\n",
    "            new_width = int(width * scaling_factor)\n",
    "            new_height = int(height * scaling_factor)\n",
    "            return image.resize((new_width, new_height), Image.LANCZOS)\n",
    "        return image\n",
    "    \n",
    "    for pdf_path in pdf_paths:\n",
    "        try:\n",
    "            if not os.path.exists(pdf_path):\n",
    "                print(f\"File not found: {pdf_path}\")\n",
    "                continue\n",
    "                \n",
    "            if not os.access(pdf_path, os.R_OK):\n",
    "                print(f\"File not readable: {pdf_path}\")\n",
    "                continue\n",
    "                \n",
    "            print(f\"Processing: {pdf_path}\")\n",
    "            images = convert_from_path(\n",
    "                pdf_path,\n",
    "                dpi=100,\n",
    "                fmt='JPEG',\n",
    "                poppler_path='/usr/bin'\n",
    "            )\n",
    "            \n",
    "            for i, image in enumerate(images):\n",
    "                resized_image = resize_image(image)\n",
    "                \n",
    "                if resized_image.mode != 'RGB':\n",
    "                    resized_image = resized_image.convert('RGB')\n",
    "                \n",
    "                quantized_image = resized_image.quantize(colors=256)\n",
    "                quantized_image = quantized_image.convert('RGB')\n",
    "                \n",
    "                img_buffer = io.BytesIO()\n",
    "                quantized_image.save(img_buffer, format='JPEG', quality=70, optimize=True)\n",
    "                img_bytes = img_buffer.getvalue()\n",
    "                base64_string = base64.b64encode(img_bytes).decode('utf-8')\n",
    "                \n",
    "                all_pages.append({\n",
    "                    'pdf_path': pdf_path,\n",
    "                    'page_number': i + 1,\n",
    "                    'base64_image': base64_string\n",
    "                })\n",
    "                \n",
    "            print(f\"Successfully processed {len(images)} pages from {pdf_path}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {pdf_path}: {str(e)}\")\n",
    "            traceback.print_exc()\n",
    "            continue\n",
    "    \n",
    "    return all_pages\n",
    "\n",
    "def process_uploaded_pdfs(files):\n",
    "    \"\"\"Convert uploaded PDF files to base64 encoded images using the provided function\"\"\"\n",
    "    if not files:\n",
    "        return None\n",
    "    \n",
    "    # Convert Gradio NamedString objects to regular strings\n",
    "    file_paths_list = []\n",
    "    for f in files:\n",
    "        if f:\n",
    "            # Convert to string to avoid Spark serialization issues\n",
    "            file_path = str(f)\n",
    "            if os.path.exists(file_path):\n",
    "                file_paths_list.append(file_path)\n",
    "    \n",
    "    if not file_paths_list:\n",
    "        return None\n",
    "    \n",
    "    print(f\"Processing {len(file_paths_list)} PDFs...\")\n",
    "    \n",
    "    # Use the provided PDF processing function\n",
    "    all_page_data = process_all_pdfs(file_paths_list)\n",
    "    \n",
    "    print(f\"Total pages processed: {len(all_page_data)}\")\n",
    "    \n",
    "    # Create Spark DataFrame\n",
    "    try:\n",
    "        pdf_schema = StructType([\n",
    "            StructField(\"pdf_path\", StringType(), True),\n",
    "            StructField(\"page_number\", IntegerType(), True),\n",
    "            StructField(\"base64_image\", StringType(), True)\n",
    "        ])\n",
    "        \n",
    "        df_pages = spark.createDataFrame(all_page_data, pdf_schema)\n",
    "        return df_pages\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating Spark DataFrame: {str(e)}\")\n",
    "        # Fallback for non-Spark environments\n",
    "        return pd.DataFrame(all_page_data)\n",
    "\n",
    "def process_document(files, query, progress=gr.Progress()):\n",
    "    \"\"\"Main processing function for Gradio interface\"\"\"\n",
    "    \n",
    "    # Validate inputs\n",
    "    if not files:\n",
    "        return \" Please upload at least one PDF document.\", \"\"\n",
    "    \n",
    "    if not query:\n",
    "        return \" Please enter a query.\", \"\"\n",
    "    \n",
    "    try:\n",
    "        # Update progress\n",
    "        progress(0.1, desc=\"Converting PDFs to images...\")\n",
    "        \n",
    "        # Convert uploaded PDFs to DataFrame format\n",
    "        medical_summary_df = process_uploaded_pdfs(files)\n",
    "        \n",
    "        progress(0.2, desc=\"Converting PDFs to images...\")\n",
    "\n",
    "        if medical_summary_df is None:\n",
    "            return \" Error processing uploaded PDF files.\", \"\"\n",
    "        \n",
    "        # Get page count for feedback\n",
    "        try:\n",
    "            page_count = medical_summary_df.count()\n",
    "        except:\n",
    "            page_count = len(medical_summary_df)\n",
    "        \n",
    "        # Update progress\n",
    "        progress(0.3, desc=f\"Processing {page_count} pages through AI agents...\")\n",
    "        \n",
    "        # Run the document ingestor\n",
    "        result = dais_ingestor_agent(\n",
    "            initial_query=query, \n",
    "            medical_summary_df=medical_summary_df\n",
    "        )\n",
    "        \n",
    "        # Update progress\n",
    "        progress(1.0, desc=\"Complete!\")\n",
    "        \n",
    "        # Format the output\n",
    "        status = f\" Document processed successfully! ({page_count} pages analyzed)\"\n",
    "        \n",
    "        # Convert result to markdown if it's not already\n",
    "        if hasattr(result, '__str__'):\n",
    "            result_markdown = str(result)\n",
    "        else:\n",
    "            result_markdown = result\n",
    "            \n",
    "        return status, result_markdown\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\" Error during processing: {str(e)}\"\n",
    "        traceback.print_exc()\n",
    "        return error_msg, \"\"\n",
    "\n",
    "def create_interface():\n",
    "    \"\"\"Create and configure the Gradio interface\"\"\"\n",
    "    \n",
    "    with gr.Blocks(title=\"DAIS Document Ingestor\", theme=gr.themes.Soft()) as demo:\n",
    "        \n",
    "        # Header\n",
    "        gr.Markdown(\n",
    "            \"\"\"\n",
    "            #  DAIS Medical Document Ingestor\n",
    "            \n",
    "            This system processes medical PDF documents using multiple AI agents to:\n",
    "            - Extract patient information from PDFs\n",
    "            - Look up insurance details\n",
    "            - Analyze document content\n",
    "            - Update database tables\n",
    "            \n",
    "            Upload your medical PDFs and specify what actions to take.\n",
    "            \"\"\"\n",
    "        )\n",
    "        \n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=1):\n",
    "                # File upload\n",
    "                file_input = gr.File(\n",
    "                    label=\"Upload Medical PDFs\",\n",
    "                    file_count=\"multiple\",\n",
    "                    file_types=[\".pdf\"],\n",
    "                    type=\"filepath\"\n",
    "                )\n",
    "                \n",
    "                # Query input\n",
    "                query_input = gr.Textbox(\n",
    "                    label=\"Query / Instructions\",\n",
    "                    placeholder=\"e.g., Update the patient_visits table with information from the document. Also, add their insurance deductible to the table.\",\n",
    "                    value=\"Update the austin_choi_demo_catalog.agents.patient_visits table with information from the document. Also, add their insurance deductible to the table.\",\n",
    "                    lines=3\n",
    "                )\n",
    "                \n",
    "                # Process button\n",
    "                process_btn = gr.Button(\" Process PDFs\", variant=\"primary\", size=\"lg\")\n",
    "            \n",
    "            with gr.Column(scale=1):\n",
    "                # Status output\n",
    "                status_output = gr.Textbox(\n",
    "                    label=\"Status\",\n",
    "                    lines=1,\n",
    "                    interactive=False\n",
    "                )\n",
    "                \n",
    "                # Result output\n",
    "                result_output = gr.Markdown(\n",
    "                    label=\"Processing Results\",\n",
    "                    value=\"*Results will appear here after processing...*\"\n",
    "                )\n",
    "        \n",
    "        # Additional information\n",
    "        with gr.Accordion(\" How it works\", open=False):\n",
    "            gr.Markdown(\n",
    "                \"\"\"\n",
    "                ### Processing Pipeline:\n",
    "                1. **PDF Conversion**: Converts PDF pages to images with optimized sizing and quality\n",
    "                2. **Document Analysis**: Classifies and extracts text from converted images using OCR\n",
    "                3. **Patient Lookup**: Searches for patient information in the Genie space\n",
    "                4. **Insurance Verification**: Finds matching insurance documents via vector search\n",
    "                5. **Text Processing**: Summarizes and extracts key information\n",
    "                6. **Database Update**: Writes the processed information to Delta tables\n",
    "                \n",
    "                ### PDF Processing Details:\n",
    "                - PDFs are converted at 100 DPI for optimal quality/performance balance\n",
    "                - Images are resized maintaining aspect ratio (max 768x2000 pixels)\n",
    "                - Each page is processed individually and encoded as base64\n",
    "                - Multi-page PDFs are fully supported\n",
    "                \n",
    "                ### Required Components:\n",
    "                - Databricks environment with appropriate permissions\n",
    "                - Poppler utilities installed for PDF conversion\n",
    "                - Access to Genie spaces and vector search endpoints\n",
    "                - Configured LLM models (Claude, Llama4)\n",
    "                - Delta table write permissions\n",
    "                \"\"\"\n",
    "            )\n",
    "        \n",
    "        # System requirements info\n",
    "        with gr.Accordion(\" System Requirements\", open=False):\n",
    "            gr.Markdown(\n",
    "                \"\"\"\n",
    "                ### Required Python packages:\n",
    "                ```python\n",
    "                pip install pdf2image\n",
    "                pip install pillow\n",
    "                ```\n",
    "                \n",
    "                ### System dependencies:\n",
    "                - Poppler utilities (for PDF conversion)\n",
    "                  - Ubuntu/Debian: `apt-get install poppler-utils`\n",
    "                  - CentOS/RHEL: `yum install poppler-utils`\n",
    "                \"\"\"\n",
    "            )\n",
    "        \n",
    "        # Event handlers\n",
    "        process_btn.click(\n",
    "            fn=process_document,\n",
    "            inputs=[file_input, query_input],\n",
    "            outputs=[status_output, result_output],\n",
    "            show_progress=True\n",
    "        )\n",
    "        \n",
    "        # Clear button\n",
    "        gr.Button(\" Clear\").click(\n",
    "            fn=lambda: (None, \n",
    "                       \"Update the austin_choi_demo_catalog.agents.patient_visits table with information from the document. Also, add their insurance deductible to the table.\",\n",
    "                       \"\",\n",
    "                       \"*Results will appear here after processing...*\"),\n",
    "            outputs=[file_input, query_input, status_output, result_output]\n",
    "        )\n",
    "    \n",
    "    return demo\n",
    "\n",
    "# Launch the interface\n",
    "if __name__ == \"__main__\":\n",
    "    demo = create_interface()\n",
    "    demo.launch(\n",
    "        share=True,  # Set to True to create a public link\n",
    "        server_name=\"0.0.0.0\",  # For Databricks environments\n",
    "        server_port=8080,\n",
    "        debug=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e3d90b67-0b31-41e6-a3ec-3e7c5bfd35a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3054820919431147,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "05_DSPy DAIS Demo",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
